{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Subset Creation from ScanNet Dataset\n",
    "\n",
    "\n",
    "#### About the ScanNet Dataset\n",
    "\n",
    "The ScanNet dataset is a collection of annotated RGB-D videos of indoor environments, primarily aimed at 3D scene understanding tasks such as segmentation, reconstruction, and semantic labeling. It includes over 2.5 million frames and more than 1,500 reconstructed 3D scenes.\n",
    "\n",
    "Key Features:\n",
    "\n",
    "- RGB-D Sequences: Captures video streams with both RGB and depth data.\n",
    "- 3D Reconstructions: Includes 3D meshes (.ply files) reconstructed from RGB-D sequences.\n",
    "- Semantic Annotations: Manually labeled scene objects with semantic categories.\n",
    "- Benchmark Splits: Defined splits for training, validation, and testing.\n",
    "\n",
    "\n",
    "Data Structure\n",
    "\n",
    "Each scene is stored in a directory named scene<spaceId>_<scanId>. Key contents include:\n",
    "\n",
    "- Reconstructed Meshes: 3D .ply files for entire scenes.\n",
    "- Frames: RGB and depth frames stored in a compressed .sens format.\n",
    "- Annotations: Semantic labels and segmentation.\n",
    "\n",
    "Associated Files:\n",
    "- scannet-labels.combined.tsv: Contains label mappings, providing the mapping between raw labels and semantic categories.\n",
    "- scannetv2_train.txt, scannetv2_val.txt, scannetv2_test.txt: Contains subsets of the training and validation data for 2d dataset.\n",
    "- train_scans.txt, val_scans.txt: Contains subsets of the training and validation data for 3d dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Data path: \n",
    "original_data = '/Volumes/datasets/scannet/scans'\n",
    "data_path = '/Volumes/projects/open3dsg/data/SCANNET'\n",
    "subset_path = '/Volumes/projects/open3dsg/data/subset_scannet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset General Overview\n",
    "\n",
    "##### Scannet 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D SCANNET OVERVIEW: \n",
      "    Number of training files: 1201\n",
      "    Number of validation files: 312\n",
      "    Number of test files: 100\n",
      "    Number of TOTAL files: 1613\n",
      "        Sample training files: ['scene0191_00', 'scene0191_01', 'scene0191_02']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [line.strip() for line in file.readlines()]\n",
    "\n",
    "train_files = load_txt_file(os.path.join(data_path, 'scannetv2_train.txt'))\n",
    "val_files = load_txt_file(os.path.join(data_path,'scannetv2_val.txt'))\n",
    "test_files = load_txt_file(os.path.join(data_path,'scannetv2_test.txt'))\n",
    "total_data = len(train_files) + len(val_files) + len(test_files)\n",
    "\n",
    "print('2D SCANNET OVERVIEW: ')\n",
    "print(f\"    Number of training files: {len(train_files)}\")\n",
    "print(f\"    Number of validation files: {len(val_files)}\")\n",
    "print(f\"    Number of test files: {len(test_files)}\")\n",
    "print(f\"    Number of TOTAL files: {total_data}\")\n",
    "print(f\"        Sample training files: {train_files[:3]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scannet 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D SCANNET OVERVIEW: \n",
      "    Number of training files: 1178\n",
      "    Number of validation files: 157\n",
      "    Number of TOTAL files: 1335\n",
      "        Sample training files: ['7272e161-a01b-20f6-8b5a-0b97efeb6545', '7272e182-a01b-20f6-89b8-3bdec0091c89', '7272e189-a01b-20f6-8a2e-05b6c8395143']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_files_3d = load_txt_file(os.path.join(data_path, 'train_scans.txt'))\n",
    "val_files_3d = load_txt_file(os.path.join(data_path,'val_scans.txt'))\n",
    "total_data = len(train_files_3d) + len(val_files_3d)\n",
    "\n",
    "print('3D SCANNET OVERVIEW: ')\n",
    "print(f\"    Number of training files: {len(train_files_3d)}\")\n",
    "print(f\"    Number of validation files: {len(val_files_3d)}\")\n",
    "print(f\"    Number of TOTAL files: {total_data}\")\n",
    "print(f\"        Sample training files: {train_files_3d[:3]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Number of unique labels: 1163\n",
      "       - ['wall' 'chair' 'floor' ... 'stove top' 'monitor from pc' 'stick']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>nyuId</th>\n",
       "      <th>nyu40id</th>\n",
       "      <th>eigen13id</th>\n",
       "      <th>nyuClass</th>\n",
       "      <th>nyu40class</th>\n",
       "      <th>eigen13class</th>\n",
       "      <th>ModelNet40</th>\n",
       "      <th>ModelNet10</th>\n",
       "      <th>ShapeNetCore55</th>\n",
       "      <th>synsetoffset</th>\n",
       "      <th>wnsynsetid</th>\n",
       "      <th>wnsynsetkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wall</td>\n",
       "      <td>7274</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>Wall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n04546855</td>\n",
       "      <td>wall.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chair</td>\n",
       "      <td>5419</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>chair</td>\n",
       "      <td>chair</td>\n",
       "      <td>Chair</td>\n",
       "      <td>chair</td>\n",
       "      <td>chair</td>\n",
       "      <td>chair</td>\n",
       "      <td>3001627.0</td>\n",
       "      <td>n03001627</td>\n",
       "      <td>chair.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>floor</td>\n",
       "      <td>3910</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>floor</td>\n",
       "      <td>floor</td>\n",
       "      <td>Floor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n03365592</td>\n",
       "      <td>floor.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>table</td>\n",
       "      <td>2664</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>table</td>\n",
       "      <td>table</td>\n",
       "      <td>Table</td>\n",
       "      <td>table</td>\n",
       "      <td>table</td>\n",
       "      <td>table</td>\n",
       "      <td>4379243.0</td>\n",
       "      <td>n04379243</td>\n",
       "      <td>table.n.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>door</td>\n",
       "      <td>1400</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>door</td>\n",
       "      <td>door</td>\n",
       "      <td>Wall</td>\n",
       "      <td>door</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n03221720</td>\n",
       "      <td>door.n.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category  count  nyuId  nyu40id  eigen13id nyuClass nyu40class eigen13class  \\\n",
       "0     wall   7274   21.0      1.0       12.0     wall       wall         Wall   \n",
       "1    chair   5419    5.0      5.0        4.0    chair      chair        Chair   \n",
       "2    floor   3910   11.0      2.0        5.0    floor      floor        Floor   \n",
       "3    table   2664   19.0      7.0       10.0    table      table        Table   \n",
       "4     door   1400   28.0      8.0       12.0     door       door         Wall   \n",
       "\n",
       "  ModelNet40 ModelNet10 ShapeNetCore55  synsetoffset wnsynsetid wnsynsetkey  \n",
       "0        NaN        NaN            NaN           NaN  n04546855   wall.n.01  \n",
       "1      chair      chair          chair     3001627.0  n03001627  chair.n.01  \n",
       "2        NaN        NaN            NaN           NaN  n03365592  floor.n.01  \n",
       "3      table      table          table     4379243.0  n04379243  table.n.02  \n",
       "4       door        NaN            NaN           NaN  n03221720   door.n.01  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(os.path.join(data_path, 'scannet-labels.combined.tsv'), sep='\\t')\n",
    "\n",
    "unique_labels = labels_df['category'].unique()\n",
    "print(f\"    Number of unique labels: {len(unique_labels)}\")\n",
    "print(f\"       - {unique_labels}\")\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identifiers, like '7272e161-a01b-20f6-8b5a-0b97efeb6545', are UUIDs (Universally Unique Identifiers) used in the ScanNet dataset to reference specific scenes. These UUIDs can be mapped to scene directories with the format `scene<spaceId>_<scanId>`, such as `scene0000_00`, using files like `scannet-labels.combined.tsv`.\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the dataset subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset_2d(input_txt_path, subset_path, subset_name, subset_size=10):\n",
    "    \"\"\"\n",
    "    Creates a subset of folders by randomly selecting a specified number of items from a given list file.\n",
    "        :param input_txt_path (str): Path to the input .txt file containing the list of folders.\n",
    "        :param subset_path (str): Path to save the subset .txt file and folders.\n",
    "        :param subset_name (str): Name for the subset (e.g., 'train', 'test', 'val').\n",
    "        :param subset_size (int): Number of folders to include in the subset.\n",
    "    \"\"\"\n",
    "    # Create folder for the subset\n",
    "    os.makedirs(subset_path, exist_ok=True)\n",
    "    print(f\"Subset folder created or already exists at: {subset_path}\")\n",
    "\n",
    "    # Load the original list of files\n",
    "    with open(input_txt_path, 'r') as file:\n",
    "        file_list = [line.strip() for line in file.readlines()]\n",
    "    print(f\"Loaded {len(file_list)} folders from {input_txt_path}.\")\n",
    "\n",
    "    # Randomly select the subset\n",
    "    random_subset = random.sample(file_list, subset_size)\n",
    "    print(f\"Randomly selected {len(random_subset)} folders for the {subset_name} subset.\")\n",
    "\n",
    "    # Store the subset list inside a .txt file\n",
    "    subset_list_file = os.path.join(subset_path, f'scannetv2_{subset_name}.txt')\n",
    "    with open(subset_list_file, 'w') as file:\n",
    "        for folder in random_subset:\n",
    "            file.write(folder + '\\n')\n",
    "    print(f\"Subset list for {subset_name} saved to: {subset_list_file}\")\n",
    "\n",
    "    # Optional: Print the selected folders\n",
    "    print(f\"Selected folders for the {subset_name} subset:\")\n",
    "    for folder in random_subset:\n",
    "        print(folder)\n",
    "    print('\\n\\n')\n",
    "\n",
    "\n",
    "def create_subset_3d(input_txt_path, subset_path, subset_name, subset_size=10):\n",
    "    \"\"\"\n",
    "    Creates a subset of folders by randomly selecting a specified number of items from a given list file.\n",
    "        :param input_txt_path (str): Path to the input .txt file containing the list of folders.\n",
    "        :param subset_path (str): Path to save the subset .txt file and folders.\n",
    "        :param subset_name (str): Name for the subset (e.g., 'train', 'val').\n",
    "        :param subset_size (int): Number of folders to include in the subset.\n",
    "    \"\"\"\n",
    "    # Create folder for the subset\n",
    "    os.makedirs(subset_path, exist_ok=True)\n",
    "    print(f\"Subset folder created or already exists at: {subset_path}\")\n",
    "\n",
    "    # Load the original list of files\n",
    "    with open(input_txt_path, 'r') as file:\n",
    "        file_list = [line.strip() for line in file.readlines()]\n",
    "    print(f\"Loaded {len(file_list)} folders from {input_txt_path}.\")\n",
    "\n",
    "    # Randomly select the subset\n",
    "    random_subset = random.sample(file_list, subset_size)\n",
    "    print(f\"Randomly selected {len(random_subset)} folders for the {subset_name} subset.\")\n",
    "\n",
    "    # Store the subset list inside a .txt file\n",
    "    subset_list_file = os.path.join(subset_path, f'{subset_name}_scans.txt')\n",
    "    with open(subset_list_file, 'w') as file:\n",
    "        for folder in random_subset:\n",
    "            file.write(folder + '\\n')\n",
    "    print(f\"Subset list for {subset_name} saved to: {subset_list_file}\")\n",
    "\n",
    "    # Optional: Print the selected folders\n",
    "    print(f\"Selected folders for the {subset_name} subset:\")\n",
    "    for folder in random_subset:\n",
    "        print(folder)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset folder created or already exists at: /Volumes/projects/open3dsg/data/subset_scannet\n",
      "Loaded 1201 folders from /Volumes/projects/open3dsg/data/SCANNET/scannetv2_train.txt.\n",
      "Randomly selected 10 folders for the train subset.\n",
      "Subset list for train saved to: /Volumes/projects/open3dsg/data/subset_scannet/scannetv2_train.txt\n",
      "Selected folders for the train subset:\n",
      "scene0547_00\n",
      "scene0480_00\n",
      "scene0173_02\n",
      "scene0336_00\n",
      "scene0242_02\n",
      "scene0687_00\n",
      "scene0092_04\n",
      "scene0359_01\n",
      "scene0039_00\n",
      "scene0038_02\n",
      "\n",
      "\n",
      "\n",
      "Subset folder created or already exists at: /Volumes/projects/open3dsg/data/subset_scannet\n",
      "Loaded 312 folders from /Volumes/projects/open3dsg/data/SCANNET/scannetv2_val.txt.\n",
      "Randomly selected 10 folders for the val subset.\n",
      "Subset list for val saved to: /Volumes/projects/open3dsg/data/subset_scannet/scannetv2_val.txt\n",
      "Selected folders for the val subset:\n",
      "scene0100_01\n",
      "scene0595_00\n",
      "scene0664_00\n",
      "scene0355_01\n",
      "scene0412_00\n",
      "scene0203_02\n",
      "scene0131_00\n",
      "scene0351_01\n",
      "scene0169_01\n",
      "scene0146_01\n",
      "\n",
      "\n",
      "\n",
      "Subset folder created or already exists at: /Volumes/projects/open3dsg/data/subset_scannet\n",
      "Loaded 100 folders from /Volumes/projects/open3dsg/data/SCANNET/scannetv2_test.txt.\n",
      "Randomly selected 10 folders for the test subset.\n",
      "Subset list for test saved to: /Volumes/projects/open3dsg/data/subset_scannet/scannetv2_test.txt\n",
      "Selected folders for the test subset:\n",
      "scene0801_00\n",
      "scene0711_00\n",
      "scene0802_00\n",
      "scene0770_00\n",
      "scene0735_00\n",
      "scene0732_00\n",
      "scene0789_00\n",
      "scene0796_00\n",
      "scene0798_00\n",
      "scene0793_00\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2D Scannet Subset \n",
    "create_subset_2d(os.path.join(data_path, 'scannetv2_train.txt'), subset_path, 'train', subset_size=10)\n",
    "create_subset_2d(os.path.join(data_path, 'scannetv2_val.txt'), subset_path, 'val', subset_size=10)\n",
    "create_subset_2d(os.path.join(data_path, 'scannetv2_test.txt'), subset_path, 'test', subset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset folder created or already exists at: /Volumes/projects/open3dsg/data/subset_scannet\n",
      "Loaded 1178 folders from /Volumes/projects/open3dsg/data/SCANNET/train_scans.txt.\n",
      "Randomly selected 10 folders for the train subset.\n",
      "Subset list for train saved to: /Volumes/projects/open3dsg/data/subset_scannet/train_scans.txt\n",
      "Selected folders for the train subset:\n",
      "2a7f9476-080c-26f9-86e9-c7ce1c76fc07\n",
      "bcb0fe2f-4f39-2c70-9eaf-a074d1b3e47b\n",
      "5341b7bf-8a66-2cdd-8794-026113b7c312\n",
      "6bde609b-9162-246f-8f90-c3d2444a5ab8\n",
      "bcb0fe15-4f39-2c70-9f48-a26b76dfe042\n",
      "5104a9c9-adc4-2a85-917e-92cb27d635fb\n",
      "1d233fea-e280-2b1a-8f15-cd60d12ae197\n",
      "20c993c1-698f-29c5-86b8-50a2a0907e2b\n",
      "4e858c81-fd93-2cb4-8469-d9226116b5de\n",
      "eee5b052-ee2d-28f4-99fd-c3c5380db25e\n",
      "\n",
      "\n",
      "\n",
      "Subset folder created or already exists at: /Volumes/projects/open3dsg/data/subset_scannet\n",
      "Loaded 157 folders from /Volumes/projects/open3dsg/data/SCANNET/val_scans.txt.\n",
      "Randomly selected 10 folders for the val subset.\n",
      "Subset list for val saved to: /Volumes/projects/open3dsg/data/subset_scannet/val_scans.txt\n",
      "Selected folders for the val subset:\n",
      "8eabc455-5af7-2f32-8606-a0bdbe6c537d\n",
      "7747a50c-9431-24e8-877d-e60c3a341cc2\n",
      "422885b3-192d-25fc-84c9-9b80eea1752d\n",
      "422885c5-192d-25fc-85e6-12a3d65c8e7b\n",
      "5341b7b3-8a66-2cdd-856d-9d70e194568b\n",
      "c2d99343-1947-2fbf-808f-92dbb7d47aa5\n",
      "9af05c68-5794-2e19-8c5a-979f448da545\n",
      "4d3d82b0-8cf4-2e04-80a8-c955ea964c2f\n",
      "0cac7532-8d6f-2d13-8cea-1e70d5ae4856\n",
      "cdcaf5bd-ddd8-2ed6-97c3-489e105e4dde\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3D Scannet Subset\n",
    "create_subset_3d(os.path.join(data_path, 'train_scans.txt'), subset_path, 'train', subset_size=10)\n",
    "create_subset_3d(os.path.join(data_path, 'val_scans.txt'), subset_path, 'val', subset_size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3dsg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
